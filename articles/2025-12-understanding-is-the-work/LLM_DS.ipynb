{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTrimq3SebxAhfo2+6rYzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yassienshaalan/applied-ml-ai-systems-articles/blob/main/LLM_DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t12Q83SOVoQY",
        "outputId": "82366544-47d0-4d13-ec2b-2ae5d0381e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/404.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m307.2/404.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pandas numpy scikit-learn xgboost optuna\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Dataset\n",
        "# =========================\n",
        "def load_adult():\n",
        "    df = fetch_openml(name=\"adult\", version=2, as_frame=True).frame\n",
        "    df = df.rename(columns={\"class\": \"target\"})\n",
        "    df[\"target\"] = df[\"target\"].astype(str).map(lambda x: 1 if \">50K\" in x else 0)\n",
        "    df = df.dropna(subset=[\"target\"]).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "df = load_adult()\n",
        "X = df.drop(columns=[\"target\"])\n",
        "y = df[\"target\"].to_numpy()\n",
        "\n",
        "# =========================\n",
        "# Preprocessing\n",
        "# =========================\n",
        "def build_preprocessor(X):\n",
        "    num = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
        "    cat = [c for c in X.columns if c not in num]\n",
        "\n",
        "    return ColumnTransformer([\n",
        "        (\"num\", Pipeline([\n",
        "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"sc\", StandardScaler())\n",
        "        ]), num),\n",
        "        (\"cat\", Pipeline([\n",
        "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"oh\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "        ]), cat)\n",
        "    ])\n",
        "\n",
        "# =========================\n",
        "# Metrics\n",
        "# =========================\n",
        "def metrics(y_true, y_score):\n",
        "    return {\n",
        "        \"auroc\": roc_auc_score(y_true, y_score),\n",
        "        \"auprc\": average_precision_score(y_true, y_score),\n",
        "        \"brier\": brier_score_loss(y_true, y_score)\n",
        "    }\n",
        "\n",
        "# =========================\n",
        "# Injections\n",
        "# =========================\n",
        "def inject_label_noise(y, rate=0.15, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    y2 = y.copy()\n",
        "    idx = rng.choice(len(y), int(len(y)*rate), replace=False)\n",
        "    y2[idx] = 1 - y2[idx]\n",
        "    return y2\n",
        "\n",
        "def inject_leakage(X, y, strength=0.98, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    leak = np.where(rng.random(len(y)) < strength, y, 1 - y)\n",
        "    X2 = X.copy()\n",
        "    X2[\"__leak__\"] = leak\n",
        "    return X2\n"
      ],
      "metadata": {
        "id": "QZwyij3vZyC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Experiment Runner\n",
        "# =========================\n",
        "SEEDS = [7, 13, 21, 42, 99]\n",
        "results = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    # IID split\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
        "    )\n",
        "    X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "        X_tr, y_tr, test_size=0.25, random_state=seed, stratify=y_tr\n",
        "    )\n",
        "\n",
        "    prep = build_preprocessor(X_tr)\n",
        "\n",
        "    models = {\n",
        "        \"logreg\": LogisticRegression(max_iter=500, n_jobs=-1),\n",
        "        \"xgb\": XGBClassifier(\n",
        "            n_estimators=700,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=4,\n",
        "            subsample=0.9,\n",
        "            colsample_bytree=0.9,\n",
        "            eval_metric=\"aucpr\",\n",
        "            tree_method=\"hist\",\n",
        "            n_jobs=-1,\n",
        "            random_state=seed\n",
        "        )\n",
        "    }\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        pipe = Pipeline([(\"prep\", prep), (\"model\", model)])\n",
        "        pipe.fit(X_tr, y_tr)\n",
        "\n",
        "        base = metrics(y_te, pipe.predict_proba(X_te)[:,1])\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"model\": model_name,\n",
        "            \"regime\": \"IID\",\n",
        "            \"injection\": \"NONE\",\n",
        "            **base\n",
        "        })\n",
        "\n",
        "        # -------- Label Noise --------\n",
        "        y_tr_noisy = inject_label_noise(y_tr, seed=seed)\n",
        "        pipe.fit(X_tr, y_tr_noisy)\n",
        "        noisy = metrics(y_te, pipe.predict_proba(X_te)[:,1])\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"model\": model_name,\n",
        "            \"regime\": \"IID\",\n",
        "            \"injection\": \"LABEL_NOISE\",\n",
        "            **noisy\n",
        "        })\n",
        "\n",
        "        # -------- Leakage --------\n",
        "        X_tr_leak = inject_leakage(X_tr, y_tr, seed=seed)\n",
        "        X_te_leak = inject_leakage(X_te, y_te, seed=seed+1)\n",
        "        prep_leak = build_preprocessor(X_tr_leak)\n",
        "        pipe = Pipeline([(\"prep\", prep_leak), (\"model\", model)])\n",
        "        pipe.fit(X_tr_leak, y_tr)\n",
        "        leak = metrics(y_te, pipe.predict_proba(X_te_leak)[:,1])\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"model\": model_name,\n",
        "            \"regime\": \"IID\",\n",
        "            \"injection\": \"LEAKAGE\",\n",
        "            **leak\n",
        "        })\n",
        "\n",
        "# =========================\n",
        "# Final Outputs\n",
        "# =========================\n",
        "results_df = pd.DataFrame(results)\n",
        "summary = (\n",
        "    results_df\n",
        "    .groupby([\"model\",\"injection\"])[[\"auroc\",\"auprc\",\"brier\"]]\n",
        "    .agg([\"mean\",\"std\"])\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "results_df.to_csv(\"final_results_long.csv\", index=False)\n",
        "summary.to_csv(\"final_summary.csv\", index=False)\n",
        "\n",
        "results_df, summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOPX1bldZ4Nd",
        "outputId": "8884cc26-9606-4056-842b-ea515e79eae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(    seed   model regime    injection     auroc     auprc     brier\n",
              " 0      7  logreg    IID         NONE  0.905609  0.762717  0.102325\n",
              " 1      7  logreg    IID  LABEL_NOISE  0.892331  0.729824  0.124998\n",
              " 2      7  logreg    IID      LEAKAGE  0.995354  0.986595  0.013306\n",
              " 3      7     xgb    IID         NONE  0.929147  0.831054  0.087475\n",
              " 4      7     xgb    IID  LABEL_NOISE  0.919190  0.812790  0.106236\n",
              " 5      7     xgb    IID      LEAKAGE  0.995626  0.987684  0.012642\n",
              " 6     13  logreg    IID         NONE  0.907755  0.768424  0.101381\n",
              " 7     13  logreg    IID  LABEL_NOISE  0.899475  0.747593  0.122863\n",
              " 8     13  logreg    IID      LEAKAGE  0.995763  0.985920  0.013242\n",
              " 9     13     xgb    IID         NONE  0.931485  0.834594  0.086293\n",
              " 10    13     xgb    IID  LABEL_NOISE  0.920976  0.818921  0.105414\n",
              " 11    13     xgb    IID      LEAKAGE  0.996194  0.988151  0.012671\n",
              " 12    21  logreg    IID         NONE  0.904831  0.767589  0.102158\n",
              " 13    21  logreg    IID  LABEL_NOISE  0.894816  0.736659  0.123573\n",
              " 14    21  logreg    IID      LEAKAGE  0.995864  0.988245  0.012437\n",
              " 15    21     xgb    IID         NONE  0.930254  0.833571  0.086785\n",
              " 16    21     xgb    IID  LABEL_NOISE  0.920803  0.818863  0.105055\n",
              " 17    21     xgb    IID      LEAKAGE  0.995960  0.988627  0.011728\n",
              " 18    42  logreg    IID         NONE  0.903848  0.762819  0.102776\n",
              " 19    42  logreg    IID  LABEL_NOISE  0.893254  0.734868  0.124456\n",
              " 20    42  logreg    IID      LEAKAGE  0.994959  0.983672  0.015056\n",
              " 21    42     xgb    IID         NONE  0.928969  0.830476  0.087499\n",
              " 22    42     xgb    IID  LABEL_NOISE  0.915437  0.812195  0.106596\n",
              " 23    42     xgb    IID      LEAKAGE  0.995576  0.986943  0.014180\n",
              " 24    99  logreg    IID         NONE  0.906600  0.765213  0.101964\n",
              " 25    99  logreg    IID  LABEL_NOISE  0.898897  0.745701  0.122432\n",
              " 26    99  logreg    IID      LEAKAGE  0.996101  0.987008  0.012490\n",
              " 27    99     xgb    IID         NONE  0.929762  0.833283  0.086801\n",
              " 28    99     xgb    IID  LABEL_NOISE  0.918414  0.817758  0.106014\n",
              " 29    99     xgb    IID      LEAKAGE  0.996241  0.987939  0.011230,\n",
              "     model    injection     auroc               auprc               brier  \\\n",
              "                             mean       std      mean       std      mean   \n",
              " 0  logreg  LABEL_NOISE  0.895754  0.003262  0.738929  0.007508  0.123664   \n",
              " 1  logreg      LEAKAGE  0.995608  0.000452  0.986288  0.001690  0.013306   \n",
              " 2  logreg         NONE  0.905728  0.001518  0.765352  0.002637  0.102121   \n",
              " 3     xgb  LABEL_NOISE  0.918964  0.002249  0.816105  0.003337  0.105863   \n",
              " 4     xgb      LEAKAGE  0.995919  0.000310  0.987869  0.000623  0.012490   \n",
              " 5     xgb         NONE  0.929923  0.001011  0.832596  0.001753  0.086971   \n",
              " \n",
              "              \n",
              "         std  \n",
              " 0  0.001069  \n",
              " 1  0.001059  \n",
              " 2  0.000511  \n",
              " 3  0.000623  \n",
              " 4  0.001127  \n",
              " 5  0.000514  )"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 4 — LLM-as-Data-Scientist (Robust JSON + Validation + Safe Loop)\n",
        "# =========================\n",
        "# What this cell does:\n",
        "# - Queries an LLM to propose a model + hyperparameters (logreg or xgb)\n",
        "# - Makes the response robust to malformed JSON using:\n",
        "#     1) JSON response_format (preferred)\n",
        "#     2) JSON extraction + minimal repair (fallback)\n",
        "#     3) \"repair\" call (last resort)\n",
        "# - Validates/clamps hyperparameters to avoid runtime crashes\n",
        "# - Runs K iterations and logs proposals + validation metrics\n",
        "#\n",
        "# Prereqs:\n",
        "# - You must have already run Cells 1–3 (so X, y, build_preprocessor(), metrics(), etc. exist)\n",
        "# - Set OPENAI_API_KEY in Colab:\n",
        "#     import os; os.environ[\"OPENAI_API_KEY\"]=\"...\"\n",
        "#\n",
        "# Output:\n",
        "# - llm_df: one row per iteration with val metrics\n",
        "# - llm_history: full proposals + metrics (for your article narrative)\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# -------------------------\n",
        "# Client\n",
        "# -------------------------\n",
        "\n",
        "client = OpenAI(api_key=\"sk-\")#provide your key and run\n",
        "\n",
        "# -------------------------\n",
        "# Packet sent to the LLM\n",
        "# -------------------------\n",
        "def dataset_packet(X, y):\n",
        "    return {\n",
        "        \"n_rows\": int(X.shape[0]),\n",
        "        \"n_features\": int(X.shape[1]),\n",
        "        \"target_rate\": float(np.mean(y)),\n",
        "        \"numeric_features\": [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])],\n",
        "        \"categorical_features\": [c for c in X.columns if not pd.api.types.is_numeric_dtype(X[c])],\n",
        "        \"missing_rate_top5\": X.isna().mean().sort_values(ascending=False).head(5).to_dict()\n",
        "    }\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are acting as a senior data scientist doing pragmatic hyperparameter search for a tabular binary classifier.\n",
        "\n",
        "Your goal: maximize validation AUPRC.\n",
        "\n",
        "You MUST return ONLY valid JSON with EXACT keys:\n",
        "{\n",
        "  \"model\": \"logreg\" or \"xgb\",\n",
        "  \"hyperparameters\": { ... }\n",
        "}\n",
        "\n",
        "Rules:\n",
        "- Keep hyperparameters conservative (do not propose exotic settings).\n",
        "- Do not include explanations or markdown.\n",
        "- Do not include any keys beyond model and hyperparameters.\n",
        "\"\"\".strip()\n",
        "\n",
        "USER_PROMPT_TEMPLATE = \"\"\"\n",
        "Dataset summary:\n",
        "{dataset_summary}\n",
        "\n",
        "History of previous attempts (iteration, model, hyperparameters, val metrics):\n",
        "{history}\n",
        "\n",
        "Propose the NEXT model and hyperparameters.\n",
        "Return ONLY JSON.\n",
        "\"\"\".strip()\n",
        "\n",
        "# -------------------------\n",
        "# Robust JSON extraction/repair\n",
        "# -------------------------\n",
        "def _extract_json_object(text: str) -> str:\n",
        "    text = text.strip()\n",
        "    if text.startswith(\"{\") and text.endswith(\"}\"):\n",
        "        return text\n",
        "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
        "    if not m:\n",
        "        raise ValueError(f\"No JSON object found in output. First 400 chars:\\n{text[:400]}\")\n",
        "    return m.group(0)\n",
        "\n",
        "def _repair_common_json_issues(s: str) -> str:\n",
        "    s = s.strip()\n",
        "    s = s.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\")\n",
        "    # heuristic single quotes -> double quotes\n",
        "    s = re.sub(r\"(?<!\\\\)'\", '\"', s)\n",
        "    # remove trailing commas\n",
        "    s = re.sub(r\",\\s*([}\\]])\", r\"\\1\", s)\n",
        "    return s\n",
        "\n",
        "def _validate_and_normalize_proposal(p: dict) -> dict:\n",
        "    if not isinstance(p, dict):\n",
        "        raise ValueError(\"Proposal is not a dict.\")\n",
        "    model = p.get(\"model\", None)\n",
        "    if model not in {\"logreg\", \"xgb\"}:\n",
        "        raise ValueError(f\"Invalid model '{model}'. Must be 'logreg' or 'xgb'.\")\n",
        "    hp = p.get(\"hyperparameters\", {})\n",
        "    if hp is None:\n",
        "        hp = {}\n",
        "    if not isinstance(hp, dict):\n",
        "        raise ValueError(\"hyperparameters must be a dict.\")\n",
        "\n",
        "    if model == \"logreg\":\n",
        "        allowed = {\"C\", \"solver\", \"penalty\", \"class_weight\", \"l1_ratio\"}\n",
        "        hp = {k: v for k, v in hp.items() if k in allowed}\n",
        "\n",
        "        C = float(hp.get(\"C\", 1.0))\n",
        "        hp[\"C\"] = float(np.clip(C, 1e-4, 1e3))\n",
        "\n",
        "        solver = str(hp.get(\"solver\", \"lbfgs\"))\n",
        "        penalty = str(hp.get(\"penalty\", \"l2\"))\n",
        "\n",
        "        if solver not in {\"lbfgs\", \"liblinear\", \"saga\", \"newton-cg\"}:\n",
        "            solver = \"lbfgs\"\n",
        "\n",
        "        # enforce compatibility\n",
        "        if solver in {\"lbfgs\", \"newton-cg\"} and penalty != \"l2\":\n",
        "            penalty = \"l2\"\n",
        "        if solver == \"liblinear\" and penalty not in {\"l1\", \"l2\"}:\n",
        "            penalty = \"l2\"\n",
        "        if solver == \"saga\" and penalty not in {\"l1\", \"l2\", \"elasticnet\"}:\n",
        "            penalty = \"l2\"\n",
        "\n",
        "        hp[\"solver\"] = solver\n",
        "        hp[\"penalty\"] = penalty\n",
        "\n",
        "    if model == \"xgb\":\n",
        "        allowed = {\n",
        "            \"n_estimators\", \"learning_rate\", \"max_depth\", \"min_child_weight\",\n",
        "            \"subsample\", \"colsample_bytree\", \"reg_lambda\", \"reg_alpha\", \"gamma\"\n",
        "        }\n",
        "        hp = {k: v for k, v in hp.items() if k in allowed}\n",
        "\n",
        "        hp[\"n_estimators\"] = int(np.clip(int(hp.get(\"n_estimators\", 600)), 100, 2000))\n",
        "        hp[\"learning_rate\"] = float(np.clip(float(hp.get(\"learning_rate\", 0.05)), 0.005, 0.3))\n",
        "        hp[\"max_depth\"] = int(np.clip(int(hp.get(\"max_depth\", 4)), 2, 10))\n",
        "        hp[\"min_child_weight\"] = float(np.clip(float(hp.get(\"min_child_weight\", 1.0)), 1.0, 20.0))\n",
        "        hp[\"subsample\"] = float(np.clip(float(hp.get(\"subsample\", 0.9)), 0.5, 1.0))\n",
        "        hp[\"colsample_bytree\"] = float(np.clip(float(hp.get(\"colsample_bytree\", 0.9)), 0.5, 1.0))\n",
        "        hp[\"reg_lambda\"] = float(np.clip(float(hp.get(\"reg_lambda\", 1.0)), 0.0, 50.0))\n",
        "        hp[\"reg_alpha\"] = float(np.clip(float(hp.get(\"reg_alpha\", 0.0)), 0.0, 10.0))\n",
        "        hp[\"gamma\"] = float(np.clip(float(hp.get(\"gamma\", 0.0)), 0.0, 10.0))\n",
        "\n",
        "    return {\"model\": model, \"hyperparameters\": hp}\n",
        "\n",
        "def query_llm(dataset_summary, history, model_name=\"gpt-4o-mini\"):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(\n",
        "            dataset_summary=json.dumps(dataset_summary, indent=2),\n",
        "            history=json.dumps(history[-6:], indent=2)  # cap history\n",
        "        )}\n",
        "    ]\n",
        "\n",
        "    # 1) Preferred: strict JSON response_format\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "            temperature=0.2,\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "        )\n",
        "        raw = resp.choices[0].message.content\n",
        "        proposal = json.loads(raw)\n",
        "        return _validate_and_normalize_proposal(proposal)\n",
        "    except Exception:\n",
        "        # 2) Fallback: extract + repair\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "            temperature=0.2,\n",
        "        )\n",
        "        raw = resp.choices[0].message.content\n",
        "\n",
        "        blob = _extract_json_object(raw)\n",
        "        blob = _repair_common_json_issues(blob)\n",
        "\n",
        "        try:\n",
        "            proposal = json.loads(blob)\n",
        "            return _validate_and_normalize_proposal(proposal)\n",
        "        except Exception:\n",
        "            # 3) Last resort: ask model to repair into valid JSON\n",
        "            resp2 = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Return ONLY valid JSON with keys: model, hyperparameters.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Repair into valid JSON only:\\n{raw}\"},\n",
        "                ],\n",
        "                temperature=0.0,\n",
        "                response_format={\"type\": \"json_object\"},\n",
        "            )\n",
        "            proposal = json.loads(resp2.choices[0].message.content)\n",
        "            return _validate_and_normalize_proposal(proposal)\n",
        "\n",
        "# -------------------------\n",
        "# Run the LLM loop on a fixed split (fair comparison)\n",
        "# -------------------------\n",
        "LLM_ITERS = 8  # bump if you want more exploration\n",
        "seed = 42\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(X_tr, y_tr, test_size=0.25, random_state=seed, stratify=y_tr)\n",
        "\n",
        "prep = build_preprocessor(X_tr)\n",
        "packet = dataset_packet(X_tr, y_tr)\n",
        "\n",
        "llm_history = []\n",
        "llm_results = []\n",
        "\n",
        "for i in range(LLM_ITERS):\n",
        "    print(f\"LLM Iteration {i+1}/{LLM_ITERS}\")\n",
        "\n",
        "    # hard guard: if the LLM fails, continue with a safe default so the suite never stops\n",
        "    try:\n",
        "        proposal = query_llm(packet, llm_history, model_name=\"gpt-4o-mini\")\n",
        "    except Exception as e:\n",
        "        print(\"LLM proposal failed; using safe fallback. Error:\", str(e))\n",
        "        proposal = {\"model\": \"xgb\", \"hyperparameters\": {\"n_estimators\": 600, \"learning_rate\": 0.05, \"max_depth\": 4}}\n",
        "        proposal = _validate_and_normalize_proposal(proposal)\n",
        "\n",
        "    if proposal[\"model\"] == \"logreg\":\n",
        "        model = LogisticRegression(max_iter=500, n_jobs=-1, **proposal[\"hyperparameters\"])\n",
        "    else:\n",
        "        model = XGBClassifier(\n",
        "            eval_metric=\"aucpr\",\n",
        "            tree_method=\"hist\",\n",
        "            n_jobs=-1,\n",
        "            random_state=seed,\n",
        "            **proposal[\"hyperparameters\"]\n",
        "        )\n",
        "\n",
        "    pipe = Pipeline([(\"prep\", prep), (\"model\", model)])\n",
        "\n",
        "    t0 = time.time()\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    train_time_s = time.time() - t0\n",
        "\n",
        "    val_scores = pipe.predict_proba(X_va)[:, 1]\n",
        "    val_m = metrics(y_va, val_scores)\n",
        "\n",
        "    llm_history.append({\n",
        "        \"iteration\": i + 1,\n",
        "        \"proposal\": proposal,\n",
        "        \"val_metrics\": val_m,\n",
        "        \"train_time_s\": train_time_s\n",
        "    })\n",
        "\n",
        "    llm_results.append({\n",
        "        \"iteration\": i + 1,\n",
        "        \"model\": proposal[\"model\"],\n",
        "        \"hyperparameters\": json.dumps(proposal[\"hyperparameters\"], sort_keys=True),\n",
        "        \"val_auroc\": val_m[\"auroc\"],\n",
        "        \"val_auprc\": val_m[\"auprc\"],\n",
        "        \"val_brier\": val_m[\"brier\"],\n",
        "        \"train_time_s\": train_time_s\n",
        "    })\n",
        "\n",
        "llm_df = pd.DataFrame(llm_results).sort_values(\"val_auprc\", ascending=False).reset_index(drop=True)\n",
        "llm_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "C96mcgnwZ79n",
        "outputId": "d4678fba-f4e3-48c8-95d0-8287630c4951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Iteration 1/8\n",
            "LLM Iteration 2/8\n",
            "LLM Iteration 3/8\n",
            "LLM Iteration 4/8\n",
            "LLM Iteration 5/8\n",
            "LLM Iteration 6/8\n",
            "LLM Iteration 7/8\n",
            "LLM Iteration 8/8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   iteration model                                    hyperparameters  \\\n",
              "0          6   xgb  {\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...   \n",
              "1          8   xgb  {\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...   \n",
              "2          7   xgb  {\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...   \n",
              "3          5   xgb  {\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...   \n",
              "4          4   xgb  {\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...   \n",
              "5          3   xgb  {\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...   \n",
              "6          2   xgb  {\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...   \n",
              "7          1   xgb  {\"colsample_bytree\": 0.8, \"gamma\": 0.0, \"learn...   \n",
              "\n",
              "   val_auroc  val_auprc  val_brier  train_time_s  \n",
              "0   0.930909   0.834651   0.086354      2.279530  \n",
              "1   0.930895   0.834583   0.086371      2.741769  \n",
              "2   0.930977   0.834575   0.086322      2.447523  \n",
              "3   0.930761   0.834284   0.086497      3.797983  \n",
              "4   0.930836   0.834256   0.086493      1.651811  \n",
              "5   0.930374   0.834090   0.086561      1.979546  \n",
              "6   0.929286   0.831238   0.087413      1.066486  \n",
              "7   0.923020   0.816605   0.091688      1.772087  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8b29bfd-8092-4e8a-96ba-91145f805fc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iteration</th>\n",
              "      <th>model</th>\n",
              "      <th>hyperparameters</th>\n",
              "      <th>val_auroc</th>\n",
              "      <th>val_auprc</th>\n",
              "      <th>val_brier</th>\n",
              "      <th>train_time_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>xgb</td>\n",
              "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...</td>\n",
              "      <td>0.930909</td>\n",
              "      <td>0.834651</td>\n",
              "      <td>0.086354</td>\n",
              "      <td>2.279530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>xgb</td>\n",
              "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...</td>\n",
              "      <td>0.930895</td>\n",
              "      <td>0.834583</td>\n",
              "      <td>0.086371</td>\n",
              "      <td>2.741769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>xgb</td>\n",
              "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...</td>\n",
              "      <td>0.930977</td>\n",
              "      <td>0.834575</td>\n",
              "      <td>0.086322</td>\n",
              "      <td>2.447523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>xgb</td>\n",
              "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...</td>\n",
              "      <td>0.930761</td>\n",
              "      <td>0.834284</td>\n",
              "      <td>0.086497</td>\n",
              "      <td>3.797983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>xgb</td>\n",
              "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...</td>\n",
              "      <td>0.930836</td>\n",
              "      <td>0.834256</td>\n",
              "      <td>0.086493</td>\n",
              "      <td>1.651811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>xgb</td>\n",
              "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...</td>\n",
              "      <td>0.930374</td>\n",
              "      <td>0.834090</td>\n",
              "      <td>0.086561</td>\n",
              "      <td>1.979546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>xgb</td>\n",
              "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0.1, \"learn...</td>\n",
              "      <td>0.929286</td>\n",
              "      <td>0.831238</td>\n",
              "      <td>0.087413</td>\n",
              "      <td>1.066486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>xgb</td>\n",
              "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0.0, \"learn...</td>\n",
              "      <td>0.923020</td>\n",
              "      <td>0.816605</td>\n",
              "      <td>0.091688</td>\n",
              "      <td>1.772087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8b29bfd-8092-4e8a-96ba-91145f805fc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8b29bfd-8092-4e8a-96ba-91145f805fc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8b29bfd-8092-4e8a-96ba-91145f805fc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fdf7676f-24bc-4d4e-9d18-1fa3c1776886\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdf7676f-24bc-4d4e-9d18-1fa3c1776886')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fdf7676f-24bc-4d4e-9d18-1fa3c1776886 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7631cb0f-5b0d-4c47-bdd5-864add6801dc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('llm_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7631cb0f-5b0d-4c47-bdd5-864add6801dc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('llm_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "llm_df",
              "summary": "{\n  \"name\": \"llm_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"iteration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8,\n          3,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"xgb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hyperparameters\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"{\\\"colsample_bytree\\\": 0.8, \\\"gamma\\\": 0.1, \\\"learning_rate\\\": 0.05, \\\"max_depth\\\": 6, \\\"min_child_weight\\\": 1.0, \\\"n_estimators\\\": 400, \\\"reg_alpha\\\": 0.1, \\\"reg_lambda\\\": 1.0, \\\"subsample\\\": 0.8}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_auroc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002729287421219016,\n        \"min\": 0.9230204949349929,\n        \"max\": 0.9309770157429068,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.930895345297003\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_auprc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0062360629409425865,\n        \"min\": 0.8166051635332007,\n        \"max\": 0.8346513805571002,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8345827016186614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_brier\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018425663121304696,\n        \"min\": 0.08632154061813921,\n        \"max\": 0.09168829526700638,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.08637140442225236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8219657047191019,\n        \"min\": 1.06648588180542,\n        \"max\": 3.797982931137085,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.7417690753936768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}